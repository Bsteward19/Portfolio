{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "    # Uses the Pandas library to read dataset from a CSV file\n",
    "    # and returns feature names, instances and labels\n",
    "def load_data_from_csv(input_csv):\n",
    "        # The read_csv Pandas function loads a csv file into a DataFrame (i.e., df)\\\n",
    "        # data structure \\n\",\n",
    "        # the first line of the csv (i.e., header=0) contains headings\n",
    "        df = pd.read_csv(input_csv, header=0) \n",
    "       # store CSV headings into a list\n",
    "        csv_headings = list(df.columns.values) \n",
    "        # the first n-1 items of the csv_headings are the feature names\n",
    "        feature_names = csv_headings[:len(csv_headings) - 1]  \n",
    "        # the last item of the csv_heading is the name of the label\\n\n",
    "        label_name = csv_headings[len(csv_headings) - 1:len(csv_headings)][0] \n",
    "      # get the numeric data of the csv file and store them in a numpy array\\n\",\n",
    "        df = df._get_numeric_data()\n",
    "        numpy_array = df.as_matrix() \n",
    "        # get number of rows and number of columns from numpy array\n",
    "        number_of_rows, number_of_columns = numpy_array.shape \n",
    "        # n-1 columns of the numpy array correspond to the instances\n",
    "        instances = numpy_array[:, 0:number_of_columns - 1]\n",
    "        # last column of the numpy array corresponds to the labels\n",
    "        labels = []\n",
    "        for label in numpy_array[:, number_of_columns - 1:number_of_columns].tolist():\n",
    "            labels.append(label[0])   \n",
    "        return feature_names, instances, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading CSV files\n"
     ]
    }
   ],
   "source": [
    "input_training_csv='Z:\\\\My Documents\\\\CIS3145\\\\CW2\\\\csv\\\\reviews_Video_Games_training.csv'\n",
    "input_test_csv='Z:\\\\My Documents\\\\CIS3145\\\\CW2\\\\csv\\\\reviews_Video_Games_test.csv'\n",
    "training_feature_names, training_instances, training_labels = load_data_from_csv(input_csv = input_training_csv)\n",
    "test_feature_names, test_instances, test_labels = load_data_from_csv(input_csv=input_test_csv)\n",
    "print('Done loading CSV files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training K-NN for K= 1\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.632     0.461     0.533      2525\n",
      "          1      0.569     0.726     0.638      2474\n",
      "\n",
      "avg / total      0.601     0.592     0.585      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 2\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.594     0.704     0.645      2525\n",
      "          1      0.628     0.509     0.562      2474\n",
      "\n",
      "avg / total      0.611     0.608     0.604      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 3\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.653     0.480     0.554      2525\n",
      "          1      0.582     0.739     0.651      2474\n",
      "\n",
      "avg / total      0.618     0.609     0.602      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 4\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.626     0.634     0.630      2525\n",
      "          1      0.622     0.614     0.618      2474\n",
      "\n",
      "avg / total      0.624     0.624     0.624      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 5\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.687     0.455     0.548      2525\n",
      "          1      0.587     0.789     0.673      2474\n",
      "\n",
      "avg / total      0.638     0.620     0.610      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 6\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.662     0.579     0.618      2525\n",
      "          1      0.619     0.698     0.656      2474\n",
      "\n",
      "avg / total      0.640     0.638     0.637      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 7\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.697     0.426     0.529      2525\n",
      "          1      0.581     0.811     0.677      2474\n",
      "\n",
      "avg / total      0.639     0.617     0.602      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 8\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.667     0.559     0.608      2525\n",
      "          1      0.614     0.715     0.661      2474\n",
      "\n",
      "avg / total      0.641     0.636     0.634      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 9\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.708     0.429     0.534      2525\n",
      "          1      0.584     0.820     0.682      2474\n",
      "\n",
      "avg / total      0.647     0.622     0.607      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 10\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.691     0.550     0.612      2525\n",
      "          1      0.620     0.749     0.678      2474\n",
      "\n",
      "avg / total      0.656     0.648     0.645      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 11\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.709     0.422     0.529      2525\n",
      "          1      0.582     0.823     0.682      2474\n",
      "\n",
      "avg / total      0.646     0.620     0.605      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 12\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.690     0.530     0.599      2525\n",
      "          1      0.612     0.757     0.677      2474\n",
      "\n",
      "avg / total      0.652     0.642     0.638      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 13\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.737     0.415     0.531      2525\n",
      "          1      0.587     0.849     0.694      2474\n",
      "\n",
      "avg / total      0.663     0.630     0.612      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 14\n",
      "Done\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.708     0.504     0.589      2525\n",
      "          1      0.609     0.788     0.687      2474\n",
      "\n",
      "avg / total      0.659     0.645     0.637      4999\n",
      "\n",
      "-----------------------------------------------------\n",
      "Training K-NN for K= 15\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Krange = [10,20,30,40,50,60,70,80,90,100]\n",
    "for i in range(1,20):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors=i)\n",
    "    print('Training K-NN for K=', i)\n",
    "    classifier.fit(training_instances, training_labels)\n",
    "    print('Done')\n",
    "    predicted_test_labels = classifier.predict(test_instances)\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(test_labels, predicted_test_labels, digits = 3))\n",
    "    #plot scatter graph\n",
    "    from sklearn.metrics import precision_recall_fscore_support as score\n",
    "    precision,recall,fscore,support=score(test_labels, predicted_test_labels,average='macro')\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.scatter(i, fscore)\n",
    "    plt.xlabel('K_value')\n",
    "    plt.ylabel('F-score')\n",
    "    print('-----------------------------------------------------')\n",
    "\n",
    "# scikit-learn k-fold cross-validation NOT NECESSARY: used to segment data for testing, which is already done as we have test and training data individually\n",
    "#from numpy import array\n",
    "#from sklearn.model_selection import KFold\n",
    "# prepare cross validation\n",
    "#kfold = KFold(3, True, 1)\n",
    "# enumerate splits\n",
    "#print('K-fold cross validation with 3 folds')\n",
    "#for train, test in kfold.split(test_instances):\n",
    "    #print('train: %s, test: %s' % (training_instances, test_instances))\n",
    "    #print('-------------------------------------')\n",
    "    #kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "    #results = model_selection.cross_val_score(estimator=KNeighborsClassifier,\n",
    "                                          #X=training_features,\n",
    "                                          #y=training_labels,\n",
    "                                          #cv=kfold,\n",
    "                                          #scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
